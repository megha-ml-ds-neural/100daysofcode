{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":3,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# TENSORFLOW "},{"metadata":{},"cell_type":"markdown","source":"*TensorFlow is an open source software library from Google, which is extensively used for\nnumerical computation. It is one of the most popularly used libraries for building deep\nlearning models. It is highly scalable and runs on multiple platforms, such as Windows,\nLinux, macOS, and Android. It was originally developed by the researchers and engineers\nof the Google Brain team.*"},{"metadata":{},"cell_type":"markdown","source":"**PACKAGES OF TENSORFLOW**"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import tensorflow as tf\nimport tensorflow.compat.v1 as tf\ntf.disable_v2_behavior()","execution_count":4,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"hello=tf.constant(\"Hello Tensorflow\")\nsess=tf.Session()\nprint(sess.run(hello))","execution_count":5,"outputs":[{"output_type":"stream","text":"b'Hello Tensorflow'\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"x=2\ny=3\nz=tf.add(x,y,name='Add')\nz","execution_count":6,"outputs":[{"output_type":"execute_result","execution_count":6,"data":{"text/plain":"<tf.Tensor 'Add:0' shape=() dtype=int32>"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"> There are two types of dependency in the computational graph, called direct and indirect\ndependency. Say we have the b node, the input of which is dependent on the output of the\na node; this type of dependency is called direct dependency and When the b node doesn't depend on the a node for its input, it is called indirect dependency\n"},{"metadata":{},"cell_type":"markdown","source":"**CREATING OWN GRAPH INSTEAD OF DEFAULT GRAPH**"},{"metadata":{"trusted":true},"cell_type":"code","source":"graph=tf.Graph()\nwith graph.as_default():\n    z=tf.add(x,y,name='Add')","execution_count":7,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"A computational graph with operations on its nodes and tensors to its edges will be\ncreated, and in order to execute the graph, we use a TensorFlow session.\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"a = tf.multiply(3,3)\nprint(a)","execution_count":8,"outputs":[{"output_type":"stream","text":"Tensor(\"Mul:0\", shape=(), dtype=int32)\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"> Instead of printing 9, the preceding code will print a TensorFlow object, Tensor(\"Mul:0\",\nshape=(), dtype=int32).\nAs we discussed earlier, whenever we import TensorFlow, a default computational graph\nwill automatically be created and all nodes will get attached to the graph. Hence, when we\nprint a, it just returns the TensorFlow object because the value for a is not computed yet, as\nthe computation graph has not been executed.\nIn order to execute the graph, we need to initialize and run the TensorFlow Session,as follows"},{"metadata":{"trusted":true},"cell_type":"code","source":"a = tf.multiply(3,3)\nsess=tf.Session()\nprint(sess.run(a))\n","execution_count":9,"outputs":[{"output_type":"stream","text":"9\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"# Variables,constants and placeholders****"},{"metadata":{},"cell_type":"markdown","source":"> Variables are containers used to store values. Variables are used as input to several other\noperations in a computational graph. A variable can be created using the tf.Variable()\nfunction, as shown in the following code:"},{"metadata":{"trusted":true},"cell_type":"code","source":"x = tf.Variable(13)\n","execution_count":10,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Let's create a variable called W, using tf.Variable(), as follows"},{"metadata":{"trusted":true},"cell_type":"code","source":"# W=tf.variable(tf.random_normal([500,111],stddev=0.35),name=\"weights\")\n","execution_count":30,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"However, after defining a variable, we need to initialize all of the variables in the\ncomputational graph. That can be done using tf.global_variables_initializer()."},{"metadata":{"trusted":true},"cell_type":"code","source":"x = tf.Variable(1212)\ninit = tf.global_variables_initializer()\nsess.run(init)\nprint(sess.run(x))","execution_count":13,"outputs":[{"output_type":"stream","text":"1212\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"> It is recommended to use tf.get_variable() rather than\ntf.Variable(), because tf.get_variable, allows you to share\nvariables, and it will make the code refactoring easier.\n"},{"metadata":{},"cell_type":"markdown","source":"when we print a,it will show error if i dont use reuse."},{"metadata":{"trusted":true},"cell_type":"code","source":"with tf.variable_scope(\"scope\",reuse=True):\n    a = tf.get_variable('x', [2])","execution_count":18,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x=tf.constant(13)","execution_count":20,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**PLACEHOLDERS AND FEED DICTIONARIES**"},{"metadata":{},"cell_type":"markdown","source":"> We can think of placeholders as variables, where we only define the type and dimension,\nbut do not assign the value. Values for the placeholders will be fed at runtime. We feed the\ndata to the computational graphs using placeholders. Placeholders are defined with no\nvalues.\nA placeholder can be defined using tf.placeholder(). It takes an optional argument\ncalled shape, which denotes the dimensions of the data. If shape is set to None, then we\ncan feed data of any size at runtime. A placeholder can be defined as follows:> **"},{"metadata":{},"cell_type":"markdown","source":"*If we run the preceding code, then it will return an error because we are trying to compute\nn, where n= m+3 and m is a placeholder whose value is not assigned. *"},{"metadata":{"trusted":true},"cell_type":"code","source":"# m=tf.placeholder(\"float\",None)\n# n=m+3\n# init = tf.global_variables_initializer()\n# sess.run(init)\n# print(sess.run(n))\n","execution_count":21,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x = tf.placeholder(\"float\", None)\ny = x +3\nwith tf.Session() as sess:\n    result = sess.run(y, feed_dict={x: 5})\n    print(result)\n","execution_count":27,"outputs":[{"output_type":"stream","text":"8.0\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"This means that x can take a matrix of any rows but with 2 columns, as shown in the\nfollowing code:"},{"metadata":{"trusted":true},"cell_type":"code","source":"x = tf.placeholder(\"float\", [None, 2])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"with tf.Session() as sess:\n    x_val=[[1,2],[3,4],[5,6],[7,8],[8,9],]\n    result=sess.run(y,feed_dict={x:x_val})\n    print(result)","execution_count":29,"outputs":[{"output_type":"stream","text":"[[ 4.  5.]\n [ 6.  7.]\n [ 8.  9.]\n [10. 11.]\n [11. 12.]]\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"# Introducing TensorBoard\nTensorBoard is TensorFlow's visualization tool, which can be used to visualize a\ncomputational graph. It can also be used to plot various quantitative metrics and the results\nof several intermediate calculations. When we are training a really deep neural network, it\nbecomes confusing when we have to debug the network. So, if we can visualize the\ncomputational graph in TensorBoard, we can easily understand such complex models,\ndebug them, and optimize them. TensorBoard also supports sharing"},{"metadata":{"trusted":true},"cell_type":"code","source":"x = tf.constant(1,name='x')\ny = tf.constant(1,name='y')\na = tf.constant(3,name='a')\nb = tf.constant(3,name='b')\n\nprod1 = tf.multiply(x,y,name='prod1')\nprod2 = tf.multiply(a,b,name='prod2')\n\nsum = tf.add(prod1,prod2,name='sum')\n\nwith tf.Session() as sess:\n    writer = tf.summary.FileWriter(logdir='./graphs',graph=sess.graph)\n    print(sess.run(sum))\n","execution_count":31,"outputs":[{"output_type":"stream","text":"10\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}